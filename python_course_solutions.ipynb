{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 1\n",
    "\n",
    "Use your newly acquired Python knowledge to make your live a bit easier. Develop a small script which helps you calculate the mass (m)for a batch of 1 litre 50 mM Ammonium hydrogen carbonate. Print the mass at the end.\n",
    "\n",
    "Molar mass (M): 79,056 g/mol   \n",
    "Concentration (c): 0.05 mol/l   \n",
    "Volume (V): 1 l   \n",
    "\n",
    "For this you need the formula\n",
    "```\n",
    "c = n / V\n",
    "n = m / M\n",
    "n = c * V\n",
    "m = n * M\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Your code goes here\n",
    "\n",
    "# It is tempting to use the same variable names as in the exercise description, but\n",
    "# 1. they are not very descriptive, V could also be voltage or velocity\n",
    "# 2. Solely uppercase variable names are usually reserved for constants (e.g. PI or G)\n",
    "\n",
    "volume: float = 1.0\n",
    "concentration: float = 0.05\n",
    "g_mol: float = 79.056\n",
    "\n",
    "mol: float = concentration * volume # mold == n from the exercise description (mol/l * l == mol)\n",
    "mass: float = g_mol * mol\n",
    "\n",
    "print(mass, \"g\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 2\n",
    "\n",
    "Make your calculation reusable and more generic by wrapping it up in a function which returns the calculated mass.   \n",
    "The argument list should be volume, concentration, molar mass.   \n",
    "Validate if your function works correctly with the data from exercise 1.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You code goes here\n",
    "\n",
    "\n",
    "def calc_m(volume: float, concentration: float, g_mol: float) -> float:\n",
    "    mol = concentration * volume\n",
    "    return g_mol * mol\n",
    "\n",
    "print(calc_m(1.0, 0.05, 79.056), \"g\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 3\n",
    "\n",
    "In a proteomic search engine we need to find the nearest mass to charge (m/z) value to a given target thousands of times. Write a function which accepts a mass spectrum (a tuple with two float lists, first the m/z values second the intensities) and a targeted value to search for. The function should return a tuple with the nearest m/z value, the corresponding intensity, the index within the list difference to the searched value.\n",
    "\n",
    "The mass is located in the file `mass_spec_json`.\n",
    "\n",
    "\n",
    "Hint: You need the built-in module `json` and the function `open()` to parse the file to a dictionary. Also checkout the functions `enumerate()` & `abs()`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# std imports\n",
    "import json\n",
    "from typing import Tuple, List\n",
    "\n",
    "# Define the mass spec tuple\n",
    "mass_spec: Tuple[List[float], List[float]] = ([], [])\n",
    "\n",
    "# `with` statement to open the file\n",
    "# it is automatically closed at the end of the `with`-block\n",
    "with open(\"mass_spec.json\") as json_file:\n",
    "    mass_json = json.load(json_file)\n",
    "    mass_spec = (mass_json[\"mz\"], mass_json[\"intensities\"])\n",
    "\n",
    "\n",
    "def find_nearest_peak(mass_spec: Tuple[List[float], List[float]], target_mz: float) -> float:\n",
    "    # Set the min index to -1 for now\n",
    "    min_idx = -1\n",
    "    # Set the min difference to infinity\n",
    "    min_diff = float(\"inf\")\n",
    "    # Iterate over the mz values in the mass spec\n",
    "    for mz_index, mz_value in enumerate(mass_spec[0]):\n",
    "        # Calculate the difference between the target mz and the current mz\n",
    "        diff = abs(target_mz - mz_value)\n",
    "        # If the difference is less than the min difference\n",
    "        if diff < min_diff:\n",
    "            # Set the min index to the current index\n",
    "            min_idx = mz_index\n",
    "            # Set the min difference to the current difference\n",
    "            min_diff = diff\n",
    "    # Return the requested tuple\n",
    "    return (mass_spec[0][min_idx], mass_spec[1][min_idx], min_idx, min_diff)\n",
    "\n",
    "\n",
    "print(find_nearest_peak(mass_spec, 638.5))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 4 : Data Analysis\n",
    "\n",
    "Let's delve into data analysis in python with pandas. You recieved a data set from your collaboration partners that work with hepatocellular carcinoma (HCC) and measured the proteomics of 19 healthy patients (C) and 19 patients that have HCC.\n",
    "\n",
    "Load the dataset into pandas. What format is the file? \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"./HCC_19_vs_19_miss.csv\", delimiter=\";\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### a) Take a look at the data\n",
    " \n",
    "Get familiar with the dataset. What are the columns, what are the rows? What type are the values? Are there missing values?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# look at first 5 rows\n",
    "print(df.head())\n",
    "# print all columns\n",
    "print(df.columns)\n",
    "# get the type of values and non-nulls\n",
    "print(df.info())\n",
    "# see how many missing values there are per entry\n",
    "print(df.isnull().sum())\n",
    "# see the shape of the dataframe\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### b) Drop rows with more than 20% missing \n",
    " \n",
    "We want to keep Proteins that 80% of the patients have to erase a bias by too many missing values, since we don't know why they are missing. Notice here that it is important to know if your values are missing at completely at random due to machine errors or non-detectability, or if the patient did not produce that protein. For simplictiy, we just apply that threshold of 20%. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dropped = df.dropna(axis=1, thresh=int(0.2*df.shape[0]))\n",
    "print(df_dropped.shape)\n",
    "print(df_dropped.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### c) Impute the rest of the missing values\n",
    " \n",
    "We want to impute the missing values for further analysis, like machine learning. Those algorithms cannot deal with missing data. There are some advanced imputation methods, especially if the cause of the missing is known, like multiple imputation by chained equations (MICE), k-nearest-neighbors (KNN), random forest imputation methods. Sometimes, using the mean or median can be absolutely sufficient. Impute the last missing values with the median!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dropped = df_dropped.drop(\"Patients\", axis=1)\n",
    "df_imputed= df_dropped.fillna(df_dropped.median())\n",
    "print(df_imputed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### d) Correlation\n",
    "\n",
    "Sometimes, correlation can mess with further analysis (machine learning) or can simply help us understand interactions with our data or gives us hints for possible biomarkers. Look at the correlation within our dataset! Look at the differences between the different correlation methods. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Corr = df_imputed.corr(method=\"kendall\")\n",
    "Corr.style.background_gradient(cmap=\"coolwarm\")\n",
    "\n",
    "\n",
    "#C1 = Corr.abs().unstack()\n",
    "#c1_sorted = C1.sort_values(ascending=True)\n",
    "\n",
    "\n",
    "#print(c1_sorted)\n",
    "#columns_above_80 = [(col1, col2)for col1, col2 in c1_sorted.index if c1_sorted[col1, col2]> 0.8 and col1!=col2] \n",
    "#print(columns_above_80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### e) Pandas Plots\n",
    "\n",
    "Check out the other different built in visualization methods pandas has to offer! \n",
    "Choose one protein and create a plot sorted by group (Control and Cancer):\n",
    "1) histogram \n",
    "2) boxplot\n",
    "3) pie plot\n",
    "\n",
    "Hint: use df.hist() for the histogram and df.plot.box() and df.plot.pie() for the other two. There are slight differences between the plot and not plot methods!\n",
    "\n",
    "Advanced: do the same for multiple or all proteins!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Histogram\n",
    "\n",
    "Hint: you will need a special argument for the function call to group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.hist(\"Q14657\",by=\"Patients\", alpha=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Boxplot\n",
    "\n",
    "Hint: you will need a special argument for the function call to group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.boxplot(column=[\"Q14657\"], by=\"Patients\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Pie Plot\n",
    "\n",
    "Hint: You will need to group manually first, sum up all intensities of the chosen protein per group and then plot it into the pandas pie plot\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pie = df.drop(\"Unnamed: 0\", axis=1)\n",
    "#df_pie = df_pie.set_index(\"Patients\")\n",
    "\n",
    "df_pie = df_pie.groupby([\"Patients\"]).sum()\n",
    "df_pie.plot.pie(y= \"Q14657\", autopct='%1.0f%%', title=\"Protein Q14657 in Control and Cancer\", colors=[\"green\", \"purple\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### f) Plotly Plots\n",
    "\n",
    "Create he same plots that you've created with pandas in plotly!\n",
    "\n",
    "1. Correlation\n",
    "2. Histogram\n",
    "3. Boxplot\n",
    "4. Pie Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the library\n",
    "import plotly.express as px\n",
    "import plotly.io as pio\n",
    "pio.renderers.default = \"iframe\" # Needed for JupyterLab on Galaxy. if you are on Visual Studio Code remove that "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Correlation\n",
    "\n",
    "Hint: You will need the correlation matrix from step d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.imshow(Corr)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Histogram\n",
    "\n",
    "Hint: you will need to pass an argument for the function call for grouping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.histogram(df, x=\"Q14657\", color = \"Patients\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Boxplot\n",
    "\n",
    "Hint: you will need to pass an argument for the function call for grouping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.box(df, x=\"Patients\", y=\"Q14657\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Pie Plot\n",
    "\n",
    "Hint: you will need to pass an argument for the function call for grouping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.pie(df, values=\"Q14657\", names=\"Patients\", title=\"Control vs Cancer\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### g) Sweetviz\n",
    "\n",
    "Sweetviz is one of a few libraries allowing for a broad inspection of the data without having to visualize anything manually. Try to use it on the original dataframe, whilst comparing the two groups!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sweetviz\n",
    "\n",
    "my_report = sweetviz.compare_intra(df, df[\"Patients\"]==\"C\", [\"Control\", \"Cancer\", ])\n",
    "\n",
    "my_report.show_notebook(layout=\"widescreen\")\n",
    "\n",
    "my_report.show_html(filepath=\"./viz.html\", open_browser=False, layout=\"widescreen\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
